{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=data_orig[data_orig.columns[:11]].Sources1.str.contains(\"\\.edu|\\.com|\\.net|\\.org|\\.uk|\\.us|\\.il|\\.ca|\\.dk|\\.in|\\.me|\\.de|\\.info\")\n",
    "\n",
    "st=\"\\.edu|\\.com|\\.net|\\.org|\\.uk|\\.us|\\.il|\\.ca|\\.dk|\\.in|\\.me|\\.de|\\.info\"\n",
    "domain_ext=st.replace(\"\\\\\",\"\").split(\"|\")\n",
    "\n",
    "domain_ext.remove(\".edu\")\n",
    "\n",
    "temp=Source.str.partition(\".edu\")[2].replace(\"\",float(\"NaN\"))\n",
    "\n",
    "for dom in domain_ext:\n",
    "    temp=temp.combine_first(Source.str.partition(dom)[2].replace(\"\",float(\"NaN\")))\n",
    "\n",
    "temp[temp.isnull()]\n",
    "\n",
    "data_aug[\"url\"]=temp\n",
    "\n",
    "data_aug[\"tilda\"]=temp.str.contains(\"~\")\n",
    "data_aug[\"pdf\"]=temp.str.contains(\".pdf\")\n",
    "\n",
    "part1=source.str.partition(\".edu\")\n",
    "data_aug[\"tilda\"]=part1[2].str.contains(\"~\")\n",
    "data_aug[\"pdf\"]=part1[2].str.contains(\".pdf\")\n",
    "\n",
    "url=temp.replace(float(\"NaN\"),\"\")\n",
    "\n",
    "Source[:20].values\n",
    "\n",
    "first_col=url.str.replace(\"^[~/]+\",'').str.findall(r\"^\\w+\")\n",
    "second_col=url.str.replace(r\"^[~/]+\\w+[./-]\",'').str.findall(r\"^\\w+\")\n",
    "third_col=url.str.replace(r\"^[~/]+\\w+[./-]\\w+[./-]+\",'').str.findall(r\"^\\w+\")\n",
    "\n",
    "def convert_list(x):\n",
    "    if len(x)>0:\n",
    "        x=x[0]\n",
    "    else:\n",
    "        x=''\n",
    "    return x \n",
    "\n",
    "first_col=first_col.apply(convert_list)\n",
    "second_col=second_col.apply(convert_list)\n",
    "third_col=third_col.apply(convert_list)\n",
    "\n",
    "data_aug[\"first_col\"]=first_col\n",
    "data_aug[\"second_col\"]=second_col\n",
    "data_aug[\"third_col\"]=third_col\n",
    "\n",
    "third_col.value_counts()\n",
    "\n",
    "non_noun_corpus=['people', 'faculty', 'directory', 'users', 'user', 'cs', '', 'cms',\n",
    "       'fac', 'pdf', 'home', 'u', 'Faculty', 'Facultydetail', 'homes',\n",
    "       'computer', 'sites', 'news', 'FacultyDetail', 'bio',\n",
    "       'engineering', 'dept', 'about', 'db', 'research', \n",
    "       'projects', 'index', 'cv', 'docs',  'eecs', 'facultydirectory',\n",
    "       'display','propernoun']\n",
    "\n",
    "for word in words:\n",
    "    if word in non_noun_corpus:\n",
    "        words.remove(word)\n",
    "    \n",
    "\n",
    "first_col_converted.values\n",
    "\n",
    "tagged_text=pos_tag(vectorizerX.vocabulary_.keys())\n",
    "\n",
    "words = [word for word,pos in tagged_text if (pos == 'NN')|(pos == 'NNP')]\n",
    "words\n",
    "\n",
    "text=word_tokenize(\" \".join(first_col_converted.values))\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizerX = CountVectorizer(min_df=1)\n",
    "\n",
    "X = vectorizerX.fit_transform(first_col_converted.values)\n",
    "\n",
    "len(vectorizerX.vocabulary_.keys())\n",
    "\n",
    "propernoun=words\n",
    "\n",
    "first_col_converted.replace(propernoun,\"propernoun\").unique()\n",
    "\n",
    "convert_list(Source[:100].str.findall(\"^(?:https?:\\/\\/)?([^:\\/\\n]+)\"))\n",
    "\n",
    "t=Source[:100].str.findall(\"^(?:https?:\\/\\/)?([^:\\/\\n]+)\")\n",
    "\n",
    "Series(Source.str.findall(\"^(?:https?:\\/\\/)?([^:\\/\\n]+)\").apply(convert_list).apply(append_http).unique()).to_csv(\"all_domain.csv\")\n",
    "\n",
    "def append_http(x):\n",
    "    x=\"http://\"+x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_aug.to_csv(os.path.join(data_dir,\"data_augmented.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_aug=pd.read_csv(os.path.join(data_dir,\"data_augmented.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#from nltk import *\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "pd.options.display.max_rows=3000\n",
    "root_dir = os.path.abspath('../..')\n",
    "task_dir= os.path.join(root_dir,'user_profile')\n",
    "data_dir=os.path.join(task_dir,'data')\n",
    "data_orig=pd.read_csv(os.path.join(data_dir,'Copy of Computer Science Professors from 55 Top US Schools (Brown University HCI project) - Data.csv'))\n",
    "\n",
    "pd.options.display.max_rows=3000\n",
    "\n",
    "data_aug=data_orig[data_orig.columns[:11]]\n",
    "\n",
    "Source=data_orig.Sources1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Source.to_csv(os.path.join(data_dir,\"data_urls.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Scrapped_urls=pd.read_csv(os.path.join(data_dir,\"all_scraped_urls.csv\"),header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scrapped_urls[1].head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Source.isin(Scrapped_urls).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows=3000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Source[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
